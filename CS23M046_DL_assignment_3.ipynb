{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9oIymAh7aKG",
        "outputId": "8248f6ee-a240-4c59-bbab-bf116b772da2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.0.1-py2.py3-none-any.whl (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.8/266.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-2.0.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from IPython.display import display\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "uEqHxH1GE9Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size,embedding_size, hidden_size,batch_size,encoder_num_layers, cell_type, bidirectional, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.batch_size=batch_size\n",
        "        self.embedding_size=embedding_size\n",
        "        self.encoder_num_layers=encoder_num_layers\n",
        "        self.cell_type = cell_type\n",
        "        self.bidirectional=bidirectional\n",
        "\n",
        "\n",
        "\n",
        "        if cell_type == \"RNN\":\n",
        "            self.rnn = nn.RNN(self.embedding_size, self.hidden_size,self.encoder_num_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        elif cell_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(self.embedding_size, self.hidden_size, self.encoder_num_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(self.embedding_size, self.hidden_size, self.encoder_num_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input_seq, hidden):\n",
        "        embedded = self.dropout((self.embedding(input_seq.long())).view(-1,self.batch_size, self.embedding_size))\n",
        "        outputs, hidden = self.rnn(embedded,hidden)\n",
        "\n",
        "\n",
        "        if self.bidirectional:\n",
        "            if self.cell_type == \"LSTM\":\n",
        "                # Dividing the hidden state into parts for each direction\n",
        "                hidden_state = hidden[0].view(2, self.encoder_num_layers, self.batch_size, self.hidden_size)\n",
        "                cell_state = hidden[0].view(2, self.encoder_num_layers, self.batch_size, self.hidden_size)\n",
        "\n",
        "                # Combining the hidden and cell states by taking their average\n",
        "                hidden = (torch.add(hidden_state[0], hidden_state[1]) / 2, torch.add(cell_state[0], cell_state[1]) / 2)\n",
        "            else:\n",
        "                # Dividing the hidden state into parts for each direction\n",
        "                hidden = hidden.view(2, self.encoder_num_layers, self.batch_size, self.hidden_size)\n",
        "\n",
        "                # Combining the hidden states by taking their average\n",
        "                hidden = torch.add(hidden[0], hidden[1]) / 2\n",
        "\n",
        "            # Splitting the output tensor into parts for each direction\n",
        "            split_tensor = torch.split(outputs, self.hidden_size, dim=-1)\n",
        "\n",
        "            # Combining the outputs by taking their average\n",
        "            output = torch.add(split_tensor[0], split_tensor[1]) / 2\n",
        "\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "\n",
        "    def initHidden(self):\n",
        "            num_directions = 2 if self.bidirectional else 1  # For bidirectional, set to 2, otherwise 1\n",
        "            if self.cell_type == \"LSTM\":\n",
        "                return (torch.zeros(self.encoder_num_layers * num_directions, self.batch_size, self.hidden_size, device=device),\n",
        "                        torch.zeros(self.encoder_num_layers * num_directions, self.batch_size, self.hidden_size, device=device))\n",
        "            else:\n",
        "                return torch.zeros(self.encoder_num_layers * num_directions, self.batch_size, self.hidden_size, device=device)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_size, embedding_size, hidden_size, batch_size, decoder_num_layers,beam_width, cell_type, dropout, MAX_LENGTH):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.decoder_num_layers = decoder_num_layers\n",
        "        self.MAX_LENGTH = MAX_LENGTH\n",
        "        self.cell_type = cell_type\n",
        "        self.dropout=dropout\n",
        "        self.beam_width = beam_width\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        if cell_type == \"RNN\":\n",
        "            self.rnn = nn.RNN(embedding_size, hidden_size, self.decoder_num_layers,dropout=dropout)\n",
        "        elif cell_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(embedding_size, hidden_size, self.decoder_num_layers, dropout=dropout)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(embedding_size, hidden_size, self.decoder_num_layers, dropout=dropout)\n",
        "\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input.long()).view(-1,self.batch_size, self.embedding_size)\n",
        "\n",
        "        output = F.relu(output)\n",
        "\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "\n",
        "        output = self.softmax(self.out(output))\n",
        "        return output, hidden\n",
        "\n",
        "\n",
        "    def beam_search(self, hidden, encoder_outputs, max_length, device):\n",
        "        sequences = [([], 0, hidden)]  # Initialize sequences with empty sequence, score 0, and hidden state\n",
        "        for _ in range(max_length):\n",
        "            all_candidates = []\n",
        "            for seq, seq_score, seq_hidden in sequences:\n",
        "                decoder_input = torch.tensor([[seq[-1]]], device=device)\n",
        "                decoder_output, decoder_hidden = self.forward(decoder_input, seq_hidden, encoder_outputs)\n",
        "                top_scores, top_indices = decoder_output.topk(self.beam_width)\n",
        "                top_scores = top_scores.squeeze().tolist()\n",
        "                top_indices = top_indices.squeeze().tolist()\n",
        "                for i in range(self.beam_width):\n",
        "                    next_token = top_indices[i]\n",
        "                    next_score = top_scores[i]\n",
        "                    all_candidates.append((seq + [next_token], seq_score + next_score, decoder_hidden))\n",
        "            ordered = sorted(all_candidates, key=lambda x: x[1], reverse=True)\n",
        "            sequences = ordered[:self.beam_width]\n",
        "        return sequences\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0zYZp7DgFMzO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "16390f85-ed78-48ec-9b71-42c1a9c8d348"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-83d0d7f0ba73>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define the model architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0membedding_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_num_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbidirectional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Datasetretrival(pathofzip, folder_name):\n",
        "    # Define the path to your zip file\n",
        "    zip_file_path = pathofzip\n",
        "\n",
        "    # Extract the contents of the zip file\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('extracted_data')\n",
        "\n",
        "    # Define the path to the extracted data directory\n",
        "    extracted_data_dir = 'extracted_data/aksharantar_sampled'\n",
        "    contents = os.listdir(extracted_data_dir)\n",
        "\n",
        "    # Initialize empty lists for train, test, and validation datasets\n",
        "    train_datasets = []\n",
        "    test_datasets = []\n",
        "    val_datasets = []\n",
        "\n",
        " # Load train, test, and validation CSV files from the specified folder\n",
        "    folder_path = os.path.join(extracted_data_dir, folder_name)\n",
        "\n",
        "    # List all files in the folder\n",
        "    folder_files = os.listdir(folder_path)\n",
        "\n",
        "    # Filter files with the specified folder name as prefix\n",
        "    foldername_prefix = folder_name + \"_\"\n",
        "    folder_files_with_prefix = [file for file in folder_files if file.startswith(foldername_prefix)]\n",
        "\n",
        "    for file in folder_files_with_prefix:\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        if 'train' in file:\n",
        "            train_datasets.append(pd.read_csv(file_path,header=None))\n",
        "        elif 'test' in file:\n",
        "            test_datasets.append(pd.read_csv(file_path,header=None))\n",
        "        elif 'val' in file:\n",
        "            val_datasets.append(pd.read_csv(file_path,header=None))\n",
        "\n",
        "    # Concatenate the loaded dataframes to create single train, test, and validation datasets\n",
        "    train_dataset = pd.concat(train_datasets, ignore_index=True)\n",
        "    test_dataset = pd.concat(test_datasets, ignore_index=True)\n",
        "    val_dataset = pd.concat(val_datasets, ignore_index=True)\n",
        "\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset"
      ],
      "metadata": {
        "id": "SbLBJ4bzz1m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vecorizeddata(data_pairs,index2char, char2index):\n",
        "\n",
        "    # Tokens\n",
        "    # 0 -> SOS\n",
        "    # 1 -> EOS\n",
        "    # 3 -> Pad\n",
        "\n",
        "    maxlength_input = 0\n",
        "    maxlength_output = 0\n",
        "\n",
        "\n",
        "    # Adding in the main index2char and char2index dictionary\n",
        "    for word_pair in data_pairs:\n",
        "        maxlength_input = max(maxlength_input, len(word_pair[0]))\n",
        "\n",
        "        for char in word_pair[0]:\n",
        "            if char not in  char2index:\n",
        "                char2index[char] = len(char2index)\n",
        "                index2char[len(index2char)] = char\n",
        "\n",
        "\n",
        "\n",
        "        maxlength_output = max(maxlength_output, len(word_pair[1]))\n",
        "\n",
        "        for char in word_pair[1]:\n",
        "            if char not in  char2index:\n",
        "                char2index[char] = len(char2index)\n",
        "                index2char[len(index2char)] = char\n",
        "\n",
        "\n",
        "    MAX_LENGTH = max(maxlength_input, maxlength_output) + 2\n",
        "\n",
        "    max_of_all = max(maxlength_input, maxlength_output)\n",
        "\n",
        "    SOS_token = 0\n",
        "    EOS_token = 1\n",
        "    PAD_token = 2\n",
        "\n",
        "    vec_pair_list = []\n",
        "    for word_pair in data_pairs:\n",
        "\n",
        "\n",
        "        vec_1 = []\n",
        "        for char in word_pair[0]:\n",
        "            vec_1.append(char2index[char])\n",
        "\n",
        "        wordvec_1 = vec_1\n",
        "        wordvec_1.append(EOS_token)\n",
        "\n",
        "        for i in range(MAX_LENGTH - len(word_pair[0])):\n",
        "            wordvec_1.append(PAD_token)\n",
        "        wordvec_1 = torch.LongTensor(wordvec_1)\n",
        "        eng_vec = wordvec_1\n",
        "\n",
        "\n",
        "        vec_2 = []\n",
        "        for char in word_pair[1]:\n",
        "            vec_2.append(char2index[char])\n",
        "\n",
        "        wordvec_2 = vec_2\n",
        "        wordvec_2.append(EOS_token)\n",
        "\n",
        "        for i in range(MAX_LENGTH - len(word_pair[1])):\n",
        "            wordvec_2.append(PAD_token)\n",
        "        wordvec_2 = torch.LongTensor(wordvec_2)\n",
        "        guj_vec = wordvec_2\n",
        "\n",
        "\n",
        "        vec_pair = (eng_vec, guj_vec)\n",
        "        vec_pair_list.append(vec_pair)\n",
        "\n",
        "    return vec_pair_list,char2index, index2char ,MAX_LENGTH\n"
      ],
      "metadata": {
        "id": "4hGs3dbCpjNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(encoder, decoder,train_loader, encoder_optimizer,decoder_optimizer,encoder_num_layers,decoder_num_layers,beam_width,cell_type,criterion,index2char,MAX_LENGTH,teacher_forcing_ratio, device):\n",
        "    total_loss = 0\n",
        "    correct=0\n",
        "    total=0\n",
        "    encoder.to(device)\n",
        "    decoder.to(device)\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    target_length=0\n",
        "\n",
        "\n",
        "    for data in tqdm(train_loader):\n",
        "\n",
        "        input_tensor, target_tensor = data\n",
        "        input_tensor = input_tensor.to(device)\n",
        "        target_tensor=target_tensor.to(device)\n",
        "        batch_size = input_tensor.shape[0]\n",
        "        input_tensor=input_tensor.T\n",
        "        target_tensor=target_tensor.T\n",
        "\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        input_length = len(input_tensor)\n",
        "        target_length = len(target_tensor)\n",
        "\n",
        "\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
        "\n",
        "\n",
        "        decoder_input = target_tensor[0]\n",
        "        # Handle different numbers of layers in the encoder and decoder\n",
        "        if encoder_num_layers != decoder_num_layers:\n",
        "            if encoder_num_layers < decoder_num_layers:\n",
        "                remaining_layers = decoder_num_layers - encoder_num_layers\n",
        "                # Copy all encoder hidden layers and then repeat the top layer\n",
        "                if cell_type == \"LSTM\":\n",
        "                    top_layer_hidden = (encoder_hidden[0][-1].unsqueeze(0), encoder_hidden[1][-1].unsqueeze(0))\n",
        "                    extra_hidden = (top_layer_hidden[0].repeat(remaining_layers, 1, 1), top_layer_hidden[1].repeat(remaining_layers, 1, 1))\n",
        "                    decoder_hidden = (torch.cat((encoder_hidden[0], extra_hidden[0]), dim=0), torch.cat((encoder_hidden[1], extra_hidden[1]), dim=0))\n",
        "                else:\n",
        "                    top_layer_hidden = encoder_hidden[-1].unsqueeze(0) #top_layer_hidden shape (1, batch_size, hidden_size)\n",
        "                    extra_hidden = top_layer_hidden.repeat(remaining_layers, 1, 1)\n",
        "                    decoder_hidden = torch.cat((encoder_hidden, extra_hidden), dim=0)\n",
        "\n",
        "            else:\n",
        "                # Slice the hidden states of the encoder to match the decoder layers\n",
        "                if cell_type == \"LSTM\":\n",
        "                    decoder_hidden = (encoder_hidden[0][-decoder_num_layers:], encoder_hidden[1][-decoder_num_layers:])\n",
        "                else :\n",
        "                    decoder_hidden = encoder_hidden[-decoder_num_layers:]\n",
        "        else:\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        pred=torch.zeros(len(target_tensor), batch_size).to(device)\n",
        "\n",
        "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "\n",
        "\n",
        "        for di in range(target_length):\n",
        "            if beam_width == 1:\n",
        "                # Standard decoding process\n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "                decoder_output = torch.squeeze(decoder_output)\n",
        "                loss += criterion(decoder_output, target_tensor[di].long())\n",
        "                topv, topi = decoder_output.topk(1)\n",
        "                topi = torch.squeeze(topi)\n",
        "                pred[di] = topi\n",
        "                if use_teacher_forcing:\n",
        "                    decoder_input = target_tensor[di]\n",
        "                else:\n",
        "                    decoder_input = topi\n",
        "            else:\n",
        "                # Beam search decoding process\n",
        "                sequences = decoder.beam_search(decoder_hidden, encoder_output, MAX_LENGTH, device)\n",
        "                # Select the top sequence from the beam search\n",
        "                top_sequence = sequences[0][0]  # top sequence with the highest score\n",
        "                for idx, token in enumerate(top_sequence):\n",
        "                    pred[idx] = token\n",
        "                    if use_teacher_forcing:\n",
        "                        decoder_input = target_tensor[di]\n",
        "                    else:\n",
        "                        decoder_input = torch.tensor([[token]], device=device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        pred = pred.T\n",
        "        act = target_tensor.T\n",
        "\n",
        "        for i in range(len(pred)):\n",
        "            f=0\n",
        "            for j in range(len(pred[i])):\n",
        "                if(pred[i][j]!=act[i][j]):\n",
        "                    f=1\n",
        "                    break\n",
        "            if(f==0):\n",
        "                correct += 1\n",
        "\n",
        "        total_loss += loss\n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "    accuracy = correct / (len(train_loader) * batch_size )\n",
        "    final_loss = total_loss /  (len(train_loader) * batch_size )\n",
        "    return   final_loss , accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "Judy7ffNQ6S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define evaluation function\n",
        "def evaluate(encoder, decoder, val_loader,encoder_num_layers,decoder_num_layers,beam_width,cell_type, criterion,index2char,MAX_LENGTH, device):\n",
        "    EOS_token=1\n",
        "    SOS_token=0\n",
        "    correct=0\n",
        "    total_loss=0\n",
        "    target_length=0\n",
        "    pred=[]\n",
        "    predictions = []\n",
        "    Input = []\n",
        "    Target = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        for data in tqdm(val_loader):\n",
        "\n",
        "            input_tensor, target_tensor = data\n",
        "            batch_size = input_tensor.shape[0]\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            target_tensor=target_tensor.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            input_tensor=input_tensor.T\n",
        "            target_tensor=target_tensor.T\n",
        "\n",
        "            encoder_hidden = encoder.initHidden()\n",
        "\n",
        "            input_length = len(input_tensor)\n",
        "            target_length = len(target_tensor)\n",
        "\n",
        "\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
        "\n",
        "\n",
        "            decoder_input = target_tensor[0]\n",
        "            # Handle different numbers of layers in the encoder and decoder\n",
        "            if encoder_num_layers != decoder_num_layers:\n",
        "                if encoder_num_layers < decoder_num_layers:\n",
        "                    remaining_layers = decoder_num_layers - encoder_num_layers\n",
        "                    # Copy all encoder hidden layers and then repeat the top layer\n",
        "                    if cell_type == \"LSTM\":\n",
        "                        top_layer_hidden = (encoder_hidden[0][-1].unsqueeze(0), encoder_hidden[1][-1].unsqueeze(0))\n",
        "                        extra_hidden = (top_layer_hidden[0].repeat(remaining_layers, 1, 1), top_layer_hidden[1].repeat(remaining_layers, 1, 1))\n",
        "                        decoder_hidden = (torch.cat((encoder_hidden[0], extra_hidden[0]), dim=0), torch.cat((encoder_hidden[1], extra_hidden[1]), dim=0))\n",
        "                    else:\n",
        "                        top_layer_hidden = encoder_hidden[-1].unsqueeze(0) #top_layer_hidden shape (1, batch_size, hidden_size)\n",
        "                        extra_hidden = top_layer_hidden.repeat(remaining_layers, 1, 1)\n",
        "                        decoder_hidden = torch.cat((encoder_hidden, extra_hidden), dim=0)\n",
        "\n",
        "                else:\n",
        "                    # Slice the hidden states of the encoder to match the decoder layers\n",
        "                    if cell_type == \"LSTM\":\n",
        "                        decoder_hidden = (encoder_hidden[0][-decoder_num_layers:], encoder_hidden[1][-decoder_num_layers:])\n",
        "                    else :\n",
        "                        decoder_hidden = encoder_hidden[-decoder_num_layers:]\n",
        "            else:\n",
        "                decoder_hidden = encoder_hidden\n",
        "\n",
        "\n",
        "            loss = 0\n",
        "            pred=torch.zeros(len(target_tensor), batch_size).to(device)\n",
        "\n",
        "\n",
        "            # for di in range(target_length):\n",
        "            #     decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            #     decoder_output = torch.squeeze(decoder_output)\n",
        "            #     loss += criterion(decoder_output, target_tensor[di].long())\n",
        "\n",
        "\n",
        "            #     topv, topi = decoder_output.topk(1)\n",
        "            #     topi = torch.squeeze(topi)\n",
        "            #     pred[di]=topi\n",
        "            #     decoder_input = topi\n",
        "            for di in range(target_length):\n",
        "                if beam_width == 1:\n",
        "                    # Standard decoding process\n",
        "                    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "                    decoder_output = torch.squeeze(decoder_output)\n",
        "                    loss += criterion(decoder_output, target_tensor[di].long())\n",
        "                    topv, topi = decoder_output.topk(1)\n",
        "                    topi = torch.squeeze(topi)\n",
        "                    pred[di] = topi\n",
        "                    decoder_input = topi\n",
        "                else:\n",
        "                    # Beam search decoding process\n",
        "                    sequences = decoder.beam_search(decoder_hidden, encoder_output, MAX_LENGTH, device)\n",
        "                    # Select the top sequence from the beam search\n",
        "                    top_sequence = sequences[0][0]  # top sequence with the highest score\n",
        "                    for idx, token in enumerate(top_sequence):\n",
        "                        pred[idx] = token\n",
        "                        decoder_input = torch.tensor([[token]], device=device)\n",
        "\n",
        "            pred = pred.T\n",
        "            act = target_tensor.T\n",
        "            act_eng = input_tensor.T\n",
        "            for i in range(batch_size):\n",
        "                pred_word=\"\"\n",
        "                input_word=\"\"\n",
        "                target_word = \"\"\n",
        "\n",
        "                f=0\n",
        "                for j in range(len(act[i])):\n",
        "\n",
        "                    if(int(pred[i][j].item()) > 2):\n",
        "                        pred_word += index2char[int(pred[i][j].item())]\n",
        "                    if(int(act[i][j].item()) > 2):\n",
        "                        target_word += index2char[int(act[i][j].item())]\n",
        "\n",
        "                    if(pred[i][j]!=act[i][j]):\n",
        "                        f=1\n",
        "\n",
        "                if(f==0):\n",
        "                    correct += 1\n",
        "\n",
        "                for j in range(len(act_eng[i])):\n",
        "\n",
        "                      if(int(act_eng[i][j].item()) > 2):\n",
        "                          input_word += index2char[int(act_eng[i][j].item())]\n",
        "\n",
        "                predictions.append(pred_word)\n",
        "                Input.append(input_word)\n",
        "                Target.append(target_word)\n",
        "\n",
        "\n",
        "        total_loss += loss\n",
        "        accuracy = correct / (len(val_loader) * batch_size )\n",
        "        final_loss = total_loss / (len(val_loader) * batch_size )\n",
        "    return  final_loss , accuracy , predictions ,Input , Target\n"
      ],
      "metadata": {
        "id": "o2hz9Lqt5bR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define training function\n",
        "def arguments(input_embedding_size,encoder_num_layers,decoder_num_layers,hidden_size,beam_width,cell_type,bidirectional,batch_normalization,batch_size,learning_rate,num_epochs,dropout,teacher_forcing_ratio,pathofzip,Folder_name):\n",
        "\n",
        "    train_dataset ,val_dataset ,test_dataset= Datasetretrival(pathofzip,Folder_name)\n",
        "\n",
        "    # Convert DataFrame to list of tuples\n",
        "    data_pairs_train = [list(row) for row in train_dataset.values]\n",
        "    data_pairs_val = [list(row) for row in val_dataset.values]\n",
        "    data_pairs_test = [list(row) for row in test_dataset.values]\n",
        "\n",
        "\n",
        "\n",
        "    index2char = {0:'<', 1: '>', 2 : '.'}\n",
        "    char2index = {'<' : 0, '>' : 1, '.' : 2 }\n",
        "\n",
        "\n",
        "    vec_pair_list_train,char2index, index2char,MAX_LENGTH_1=vecorizeddata(data_pairs_train,index2char, char2index)\n",
        "    vec_pair_list_val,_,_,MAX_LENGTH_2=vecorizeddata(data_pairs_val,index2char, char2index)\n",
        "    vec_pair_list_test,_,_,MAX_LENGTH_3=vecorizeddata(data_pairs_test,index2char, char2index)\n",
        "\n",
        "\n",
        "    predictions = []\n",
        "    Input = []\n",
        "    Target = []\n",
        "\n",
        "\n",
        "    MAX_LENGTH= 30\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_loader = DataLoader(vec_pair_list_train, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(vec_pair_list_val, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(vec_pair_list_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Define model\n",
        "    encoder = Encoder(len(char2index),input_embedding_size, hidden_size,batch_size, encoder_num_layers, cell_type,bidirectional, dropout).to(device)\n",
        "    decoder = Decoder(len(char2index),input_embedding_size, hidden_size,batch_size, decoder_num_layers,beam_width, cell_type, dropout,MAX_LENGTH).to(device)\n",
        "    #model = Seq2Seq(encoder, decoder, encoder_num_layers, decoder_num_layers,batch_size, hidden_size,bidirectional, cell_type,device).to(device)\n",
        "\n",
        "    output_predictions=torch.tensor([]).to(device)\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "        # Train the model\n",
        "        train_loss, train_accuracy = train(encoder,decoder, train_loader, encoder_optimizer,decoder_optimizer,encoder_num_layers,decoder_num_layers,beam_width,cell_type, criterion,index2char,MAX_LENGTH,teacher_forcing_ratio, device)\n",
        "\n",
        "        # Validation loop\n",
        "        val_loss, val_accuracy,predictions ,Input , Target = evaluate(encoder,decoder, val_loader,encoder_num_layers,decoder_num_layers,beam_width,cell_type, criterion,index2char,MAX_LENGTH, device)\n",
        "\n",
        "        # Log metrics to Weights & Biases\n",
        "        # wandb.log({\n",
        "        #     \"Epoch\": epoch + 1,\n",
        "        #     \"Train_Accuracy\": train_accuracy,\n",
        "        #     \"Train_Loss\": train_loss,\n",
        "        #     \"Val_Accuracy\": val_accuracy,\n",
        "        #     \"Val_Loss\": val_loss\n",
        "        # })\n",
        "\n",
        "        # Print epoch results\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs},\\n Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f},\\n Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    print(f\"\\n Predictions Generated by current sweep and actual output:\\n\")\n",
        "    dataframe = pd.DataFrame({\"INPUT\": Input, \"PREDICTED\": predictions,\"ACTUAL\":Target})\n",
        "    dataframe.to_csv(\"predictions.csv\", index=False)\n",
        "    data = pd.read_csv(\"predictions.csv\",header=None)\n",
        "    #files.download(\"predictions.csv\")\n",
        "    display(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "Q-ogr2f5Hk8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arguments(32,2,2,1024,1,\"RNN\",True,\"Yes\",128,0.001,1,0.2,0.5,'/content/sample_data/aksharantar_sampled.zip','guj')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 562
        },
        "id": "AdPJ4R11AYdO",
        "outputId": "7707d463-a84d-4e1b-e727-e2cb6faeb89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 400/400 [00:43<00:00,  9.27it/s]\n",
            "100%|██████████| 32/32 [00:11<00:00,  2.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1,\n",
            " Train Loss: 0.2607, Train Accuracy: 0.0000,\n",
            " Val Loss: 0.0060, Val Accuracy: 0.0000\n",
            "\n",
            " Predictions Generated by current sweep and actual output:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                 0          1            2\n",
              "0            INPUT  PREDICTED       ACTUAL\n",
              "1         vasteena      વાા્ન       વસતીના\n",
              "2        gardanana     ગા્્ના       ગરદનના\n",
              "3            roqsa      રેા્ન        રોક્સ\n",
              "4     suparastarsa     સુર્ના  સુપરસ્ટાર્સ\n",
              "...            ...        ...          ...\n",
              "4092      humirsir     હુર્ના       હમીરસર\n",
              "4093        batata      બા્્ન        બટાટા\n",
              "4094       dhovaai     ધિર્ના        ધોવાઇ\n",
              "4095    daridrataa     દા્્ના     દરિદ્રતા\n",
              "4096   ekantbharya     એ્રોન્   એકાંતભર્યા\n",
              "\n",
              "[4097 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fa5a630f-a14c-4eda-86ab-eb6007d2e717\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INPUT</td>\n",
              "      <td>PREDICTED</td>\n",
              "      <td>ACTUAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vasteena</td>\n",
              "      <td>વાા્ન</td>\n",
              "      <td>વસતીના</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gardanana</td>\n",
              "      <td>ગા્્ના</td>\n",
              "      <td>ગરદનના</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>roqsa</td>\n",
              "      <td>રેા્ન</td>\n",
              "      <td>રોક્સ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>suparastarsa</td>\n",
              "      <td>સુર્ના</td>\n",
              "      <td>સુપરસ્ટાર્સ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4092</th>\n",
              "      <td>humirsir</td>\n",
              "      <td>હુર્ના</td>\n",
              "      <td>હમીરસર</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4093</th>\n",
              "      <td>batata</td>\n",
              "      <td>બા્્ન</td>\n",
              "      <td>બટાટા</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4094</th>\n",
              "      <td>dhovaai</td>\n",
              "      <td>ધિર્ના</td>\n",
              "      <td>ધોવાઇ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4095</th>\n",
              "      <td>daridrataa</td>\n",
              "      <td>દા્્ના</td>\n",
              "      <td>દરિદ્રતા</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4096</th>\n",
              "      <td>ekantbharya</td>\n",
              "      <td>એ્રોન્</td>\n",
              "      <td>એકાંતભર્યા</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4097 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa5a630f-a14c-4eda-86ab-eb6007d2e717')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fa5a630f-a14c-4eda-86ab-eb6007d2e717 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fa5a630f-a14c-4eda-86ab-eb6007d2e717');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-68dac9d4-96b2-48bf-8444-ca27ca2678e6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-68dac9d4-96b2-48bf-8444-ca27ca2678e6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-68dac9d4-96b2-48bf-8444-ca27ca2678e6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"arguments(32,2,2,1024,\\\"RNN\\\",True,\\\"Yes\\\",128,0\",\n  \"rows\": 4097,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4087,\n        \"samples\": [\n          \"pahormaa\",\n          \"laleemaa\",\n          \"karoonateeka\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 335,\n        \"samples\": [\n          \"\\u0aae\\u0acb\\u0a95\\u0acd\\u0aa8\",\n          \"\\u0a9a\\u0acb\\u0ab2\\u0acd\\u0aa8\",\n          \"\\u0ab5\\u0ac7\\u0ab0\\u0acd\\u0aa8\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2521,\n        \"samples\": [\n          \"\\u0a85\\u0a82\\u0a97\\u0acd\\u0ab0\\u0ac7\\u0a9c\\u0ac0\\u0aae\\u0abe\\u0a82\\u0aa5\\u0ac0\",\n          \"\\u0aac\\u0aac\\u0ab2\",\n          \"\\u0aad\\u0ac2\\u0aa4\\u0abe\\u0aa8\\u0aae\\u0abe\\u0a82\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#wandb.login()"
      ],
      "metadata": {
        "id": "_uycA2lZ1b22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Define hyperparameters to sweep\n",
        "# sweep_config = {\n",
        "#     \"method\": \"bayes\",\n",
        "#     'name'  : 'Train Dataset Run',\n",
        "#     'metric': {'goal': 'maximize', 'name': 'Val_Accuracy'},\n",
        "#     \"parameters\": {\n",
        "#         \"input_embedding_size\": {\"values\": [16, 32, 64, 256]},\n",
        "#         \"encoder_num_layers\": {\"values\": [1, 2, 3]},\n",
        "#         \"decoder_num_layers\": {\"values\": [1, 2, 3]},\n",
        "#         \"hidden_size\": {\"values\": [16, 32, 64, 256]},\n",
        "#         \"beam_width\": {\"values\": [1,32, 64]},\n",
        "#         \"cell_type\": {\"values\": [\"RNN\", \"GRU\", \"LSTM\"]},\n",
        "#         \"bidirectional\": {\"values\": [True, False]},\n",
        "#         \"batch_normalization\": {\"values\": ['Yes', 'No']},\n",
        "#         \"batch_size\": {\"values\": [32, 64]},\n",
        "#         \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
        "#         \"num_epochs\": {\"values\": [5,10]},\n",
        "#         \"dropout\": {\"values\": [0.2, 0.3]},\n",
        "#         \"teacher_forcing_ratio\" : {\"values\":[0.5]}\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# # Initialize wandb sweep\n",
        "# sweep_id = wandb.sweep(sweep=sweep_config, project=\"DL_Assignment_3_CS23M046\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zLWJQje5FQ2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def main_1():\n",
        "\n",
        "#     # Initialize wandb\n",
        "#     with wandb.init() as run:\n",
        "\n",
        "#         config = wandb.config\n",
        "\n",
        "#         run_name=str(config.cell_type)+\"_embedding_\"+str(config.input_embedding_size)+\"_hidden_size_\"+str(config.hidden_size)+\"_beam_size_\"+str(config.beam_width)+\"_Encoder_layers_\"+str(config.encoder_num_layers)+\"_Decoder_layers_\"+str(config.decoder_num_layers)\n",
        "#         wandb.run.name=run_name\n",
        "\n",
        "#         pathofzip='/content/sample_data/aksharantar_sampled.zip'\n",
        "#         Folder_name='guj'\n",
        "\n",
        "#         arguments(config.input_embedding_size,config.encoder_num_layers,config.decoder_num_layers,config.hidden_size,config.beam_width,config.cell_type,config.bidirectional,config.batch_normalization,config.batch_size,config.learning_rate,config.num_epochs,,config.dropout,config.teacher_forcing_ratio,pathofzip,Folder_name)\n",
        "\n",
        "\n",
        "\n",
        "# # Run sweep\n",
        "# wandb.agent(sweep_id, function=main_1, count=5)\n",
        "\n",
        "# wandb.finish()"
      ],
      "metadata": {
        "id": "2FWR7pg3Mf55"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}