{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f877006e5fce43809a9c660ea128e717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68694ac4ff3e4d01b6beb9ec6a99f145",
              "IPY_MODEL_19bed0682a81473a8a2038001ed0d495"
            ],
            "layout": "IPY_MODEL_5e07f34785e447cdb42ac3f2c6505f34"
          }
        },
        "68694ac4ff3e4d01b6beb9ec6a99f145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7759284d5e84508b5fb576b6720d1f1",
            "placeholder": "​",
            "style": "IPY_MODEL_8a74a887c3c74c1a900303b73934fc63",
            "value": "0.014 MB of 0.014 MB uploaded\r"
          }
        },
        "19bed0682a81473a8a2038001ed0d495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc69c175a4a949d88174ab5695a91cac",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_413fbe6342674d8386042992fd26fe44",
            "value": 1
          }
        },
        "5e07f34785e447cdb42ac3f2c6505f34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7759284d5e84508b5fb576b6720d1f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a74a887c3c74c1a900303b73934fc63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc69c175a4a949d88174ab5695a91cac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "413fbe6342674d8386042992fd26fe44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9oIymAh7aKG",
        "outputId": "38d11bf8-cc4e-4fc9-be2c-3e446e03555b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.16.6-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.1.1-py2.py3-none-any.whl (277 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.3/277.3 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.43 docker-pycreds-0.4.0 gitdb-4.0.11 sentry-sdk-2.1.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.16.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.nn.functional as F\n",
        "import wandb\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from google.colab import files\n",
        "from IPython.display import display\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "uEqHxH1GE9Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_size,embedding_size, hidden_size,batch_size,encoder_num_layers, cell_type, bidirectional, dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.batch_size=batch_size\n",
        "        self.embedding_size=embedding_size\n",
        "        self.encoder_num_layers=encoder_num_layers\n",
        "        self.cell_type = cell_type\n",
        "        self.bidirectional=bidirectional\n",
        "\n",
        "\n",
        "\n",
        "        if cell_type == \"RNN\":\n",
        "            self.rnn = nn.RNN(self.embedding_size, self.hidden_size,self.encoder_num_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        elif cell_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(self.embedding_size, self.hidden_size, self.encoder_num_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(self.embedding_size, self.hidden_size, self.encoder_num_layers, bidirectional=bidirectional, dropout=dropout)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input_seq, hidden):\n",
        "        embedded = self.dropout((self.embedding(input_seq.long())).view(-1,self.batch_size, self.embedding_size))\n",
        "        outputs, hidden = self.rnn(embedded,hidden)\n",
        "\n",
        "\n",
        "        if self.bidirectional:\n",
        "            if self.cell_type == \"LSTM\":\n",
        "                # Dividing the hidden state into parts for each direction\n",
        "                hidden_state = hidden[0].view(2, self.encoder_num_layers, self.batch_size, self.hidden_size)\n",
        "                cell_state = hidden[0].view(2, self.encoder_num_layers, self.batch_size, self.hidden_size)\n",
        "\n",
        "                # Combining the hidden and cell states by taking their average\n",
        "                hidden = (torch.add(hidden_state[0], hidden_state[1]) / 2, torch.add(cell_state[0], cell_state[1]) / 2)\n",
        "            else:\n",
        "                # Dividing the hidden state into parts for each direction\n",
        "                hidden = hidden.view(2, self.encoder_num_layers, self.batch_size, self.hidden_size)\n",
        "\n",
        "                # Combining the hidden states by taking their average\n",
        "                hidden = torch.add(hidden[0], hidden[1]) / 2\n",
        "\n",
        "            # Splitting the output tensor into parts for each direction\n",
        "            split_tensor = torch.split(outputs, self.hidden_size, dim=-1)\n",
        "\n",
        "            # Combining the outputs by taking their average\n",
        "            output = torch.add(split_tensor[0], split_tensor[1]) / 2\n",
        "\n",
        "\n",
        "        return outputs, hidden\n",
        "\n",
        "\n",
        "\n",
        "    def initHidden(self):\n",
        "            num_directions = 2 if self.bidirectional else 1  # For bidirectional, set to 2, otherwise 1\n",
        "            if self.cell_type == \"LSTM\":\n",
        "                return (torch.zeros(self.encoder_num_layers * num_directions, self.batch_size, self.hidden_size, device=device),\n",
        "                        torch.zeros(self.encoder_num_layers * num_directions, self.batch_size, self.hidden_size, device=device))\n",
        "            else:\n",
        "                return torch.zeros(self.encoder_num_layers * num_directions, self.batch_size, self.hidden_size, device=device)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_size, embedding_size, hidden_size, batch_size, decoder_num_layers, cell_type, dropout, MAX_LENGTH):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.batch_size = batch_size\n",
        "        self.embedding_size = embedding_size\n",
        "        self.decoder_num_layers = decoder_num_layers\n",
        "        self.MAX_LENGTH = MAX_LENGTH\n",
        "        self.cell_type = cell_type\n",
        "        self.dropout=dropout\n",
        "\n",
        "        self.embedding = nn.Embedding(output_size, embedding_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        if cell_type == \"RNN\":\n",
        "            self.rnn = nn.RNN(embedding_size, hidden_size, self.decoder_num_layers,dropout=dropout)\n",
        "        elif cell_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(embedding_size, hidden_size, self.decoder_num_layers, dropout=dropout)\n",
        "        elif cell_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(embedding_size, hidden_size, self.decoder_num_layers, dropout=dropout)\n",
        "\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "        self.softmax = nn.LogSoftmax(dim=2)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.embedding(input.long()).view(-1,self.batch_size, self.embedding_size)\n",
        "\n",
        "        output = F.relu(output)\n",
        "\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "\n",
        "        output = self.softmax(self.out(output))\n",
        "        return output, hidden\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0zYZp7DgFMzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Datasetretrival(pathofzip, folder_name):\n",
        "    # Define the path to your zip file\n",
        "    zip_file_path = pathofzip\n",
        "\n",
        "    # Extract the contents of the zip file\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('extracted_data')\n",
        "\n",
        "    # Define the path to the extracted data directory\n",
        "    extracted_data_dir = 'extracted_data/aksharantar_sampled'\n",
        "    contents = os.listdir(extracted_data_dir)\n",
        "\n",
        "    # Initialize empty lists for train, test, and validation datasets\n",
        "    train_datasets = []\n",
        "    test_datasets = []\n",
        "    val_datasets = []\n",
        "\n",
        " # Load train, test, and validation CSV files from the specified folder\n",
        "    folder_path = os.path.join(extracted_data_dir, folder_name)\n",
        "\n",
        "    # List all files in the folder\n",
        "    folder_files = os.listdir(folder_path)\n",
        "\n",
        "    # Filter files with the specified folder name as prefix\n",
        "    foldername_prefix = folder_name + \"_\"\n",
        "    folder_files_with_prefix = [file for file in folder_files if file.startswith(foldername_prefix)]\n",
        "\n",
        "    for file in folder_files_with_prefix:\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        if 'train' in file:\n",
        "            train_datasets.append(pd.read_csv(file_path,header=None))\n",
        "        elif 'test' in file:\n",
        "            test_datasets.append(pd.read_csv(file_path,header=None))\n",
        "        elif 'val' in file:\n",
        "            val_datasets.append(pd.read_csv(file_path,header=None))\n",
        "\n",
        "    # Concatenate the loaded dataframes to create single train, test, and validation datasets\n",
        "    train_dataset = pd.concat(train_datasets, ignore_index=True)\n",
        "    test_dataset = pd.concat(test_datasets, ignore_index=True)\n",
        "    val_dataset = pd.concat(val_datasets, ignore_index=True)\n",
        "\n",
        "\n",
        "    return train_dataset, val_dataset, test_dataset"
      ],
      "metadata": {
        "id": "SbLBJ4bzz1m_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vecorizeddata(data_pairs,index2char, char2index):\n",
        "\n",
        "    # Tokens\n",
        "    # 0 -> SOS\n",
        "    # 1 -> EOS\n",
        "    # 3 -> Pad\n",
        "\n",
        "    maxlength_input = 0\n",
        "    maxlength_output = 0\n",
        "\n",
        "\n",
        "    # Adding in the main index2char and char2index dictionary\n",
        "    for word_pair in data_pairs:\n",
        "        maxlength_input = max(maxlength_input, len(word_pair[0]))\n",
        "\n",
        "        for char in word_pair[0]:\n",
        "            if char not in  char2index:\n",
        "                char2index[char] = len(char2index)\n",
        "                index2char[len(index2char)] = char\n",
        "\n",
        "\n",
        "\n",
        "        maxlength_output = max(maxlength_output, len(word_pair[1]))\n",
        "\n",
        "        for char in word_pair[1]:\n",
        "            if char not in  char2index:\n",
        "                char2index[char] = len(char2index)\n",
        "                index2char[len(index2char)] = char\n",
        "\n",
        "\n",
        "    MAX_LENGTH = max(maxlength_input, maxlength_output) + 2\n",
        "\n",
        "    max_of_all = max(maxlength_input, maxlength_output)\n",
        "\n",
        "    SOS_token = 0\n",
        "    EOS_token = 1\n",
        "    PAD_token = 2\n",
        "\n",
        "    vec_pair_list = []\n",
        "    for word_pair in data_pairs:\n",
        "\n",
        "\n",
        "        vec_1 = []\n",
        "        for char in word_pair[0]:\n",
        "            vec_1.append(char2index[char])\n",
        "\n",
        "        wordvec_1 = vec_1\n",
        "        wordvec_1.append(EOS_token)\n",
        "\n",
        "        for i in range(MAX_LENGTH - len(word_pair[0])):\n",
        "            wordvec_1.append(PAD_token)\n",
        "        wordvec_1 = torch.LongTensor(wordvec_1)\n",
        "        eng_vec = wordvec_1\n",
        "\n",
        "\n",
        "        vec_2 = []\n",
        "        for char in word_pair[1]:\n",
        "            vec_2.append(char2index[char])\n",
        "\n",
        "        wordvec_2 = vec_2\n",
        "        wordvec_2.append(EOS_token)\n",
        "\n",
        "        for i in range(MAX_LENGTH - len(word_pair[1])):\n",
        "            wordvec_2.append(PAD_token)\n",
        "        wordvec_2 = torch.LongTensor(wordvec_2)\n",
        "        guj_vec = wordvec_2\n",
        "\n",
        "\n",
        "        vec_pair = (eng_vec, guj_vec)\n",
        "        vec_pair_list.append(vec_pair)\n",
        "\n",
        "    return vec_pair_list,char2index, index2char ,MAX_LENGTH\n"
      ],
      "metadata": {
        "id": "4hGs3dbCpjNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(encoder, decoder,train_loader, encoder_optimizer,decoder_optimizer,encoder_num_layers,decoder_num_layers,cell_type,criterion,char2index,index2char,MAX_LENGTH,teacher_forcing_ratio,attention,beam_width, device):\n",
        "    total_loss = 0\n",
        "    correct=0\n",
        "    total=0\n",
        "    encoder.to(device)\n",
        "    decoder.to(device)\n",
        "    encoder.train()\n",
        "    decoder.train()\n",
        "    target_length=0\n",
        "\n",
        "\n",
        "    for data in tqdm(train_loader):\n",
        "\n",
        "        input_tensor, target_tensor = data\n",
        "        input_tensor = input_tensor.to(device)\n",
        "        target_tensor=target_tensor.to(device)\n",
        "        batch_size = input_tensor.shape[0]\n",
        "        input_tensor=input_tensor.T\n",
        "        target_tensor=target_tensor.T\n",
        "\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        input_length = len(input_tensor)\n",
        "        target_length = len(target_tensor)\n",
        "\n",
        "\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
        "\n",
        "\n",
        "        decoder_input = target_tensor[0]\n",
        "        # Handle different numbers of layers in the encoder and decoder\n",
        "        if encoder_num_layers != decoder_num_layers:\n",
        "            if encoder_num_layers < decoder_num_layers:\n",
        "                remaining_layers = decoder_num_layers - encoder_num_layers\n",
        "                # Copy all encoder hidden layers and then repeat the top layer\n",
        "                if cell_type == \"LSTM\":\n",
        "                    top_layer_hidden = (encoder_hidden[0][-1].unsqueeze(0), encoder_hidden[1][-1].unsqueeze(0))\n",
        "                    extra_hidden = (top_layer_hidden[0].repeat(remaining_layers, 1, 1), top_layer_hidden[1].repeat(remaining_layers, 1, 1))\n",
        "                    decoder_hidden = (torch.cat((encoder_hidden[0], extra_hidden[0]), dim=0), torch.cat((encoder_hidden[1], extra_hidden[1]), dim=0))\n",
        "                else:\n",
        "                    top_layer_hidden = encoder_hidden[-1].unsqueeze(0) #top_layer_hidden shape (1, batch_size, hidden_size)\n",
        "                    extra_hidden = top_layer_hidden.repeat(remaining_layers, 1, 1)\n",
        "                    decoder_hidden = torch.cat((encoder_hidden, extra_hidden), dim=0)\n",
        "\n",
        "            else:\n",
        "                # Slice the hidden states of the encoder to match the decoder layers\n",
        "                if cell_type == \"LSTM\":\n",
        "                    decoder_hidden = (encoder_hidden[0][-decoder_num_layers:], encoder_hidden[1][-decoder_num_layers:])\n",
        "                else :\n",
        "                    decoder_hidden = encoder_hidden[-decoder_num_layers:]\n",
        "        else:\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "        pred=torch.zeros(len(target_tensor), batch_size).to(device)\n",
        "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
        "\n",
        "        if use_teacher_forcing:\n",
        "\n",
        "            for di in range(target_length):\n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "                decoder_output = torch.squeeze(decoder_output)\n",
        "                loss += criterion(decoder_output, target_tensor[di].long())\n",
        "\n",
        "\n",
        "                topv, topi = decoder_output.topk(1)\n",
        "                topi=torch.squeeze(topi)\n",
        "                pred[di]=topi\n",
        "\n",
        "                decoder_input = target_tensor[di]\n",
        "\n",
        "\n",
        "        else:\n",
        "\n",
        "            for di in range(target_length):\n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "                decoder_output = torch.squeeze(decoder_output)\n",
        "                loss += criterion(decoder_output, target_tensor[di].long())\n",
        "\n",
        "\n",
        "                topv, topi = decoder_output.topk(1)\n",
        "                topi = torch.squeeze(topi)\n",
        "                pred[di]=topi\n",
        "                decoder_input = topi\n",
        "\n",
        "        pred = pred.T\n",
        "        act = target_tensor.T\n",
        "\n",
        "        for i in range(len(pred)):\n",
        "            f=0\n",
        "            for j in range(len(pred[i])):\n",
        "                if(pred[i][j]!=act[i][j]):\n",
        "                    f=1\n",
        "                    break\n",
        "            if(f==0):\n",
        "                correct += 1\n",
        "\n",
        "        total_loss += loss\n",
        "        loss.backward()\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "\n",
        "\n",
        "    accuracy = correct / (len(train_loader) * batch_size )\n",
        "    final_loss = total_loss /  (len(train_loader) * batch_size )\n",
        "    return   final_loss , accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "Judy7ffNQ6S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define evaluation function\n",
        "def evaluate(encoder, decoder, val_loader,encoder_num_layers,decoder_num_layers,cell_type, criterion,char2index,index2char,MAX_LENGTH,attention,beam_width, device):\n",
        "    EOS_token=1\n",
        "    SOS_token=0\n",
        "    correct=0\n",
        "    total_loss=0\n",
        "    target_length=0\n",
        "    pred=[]\n",
        "    predictions = []\n",
        "    Input = []\n",
        "    Target = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        encoder.eval()\n",
        "        decoder.eval()\n",
        "        for data in tqdm(val_loader):\n",
        "\n",
        "            input_tensor, target_tensor = data\n",
        "            batch_size = input_tensor.shape[0]\n",
        "            input_tensor = input_tensor.to(device)\n",
        "            target_tensor=target_tensor.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            input_tensor=input_tensor.T\n",
        "            target_tensor=target_tensor.T\n",
        "\n",
        "            encoder_hidden = encoder.initHidden()\n",
        "\n",
        "            input_length = len(input_tensor)\n",
        "            target_length = len(target_tensor)\n",
        "\n",
        "\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden)\n",
        "\n",
        "\n",
        "            decoder_input = target_tensor[0]\n",
        "            # Handle different numbers of layers in the encoder and decoder\n",
        "            if encoder_num_layers != decoder_num_layers:\n",
        "                if encoder_num_layers < decoder_num_layers:\n",
        "                    remaining_layers = decoder_num_layers - encoder_num_layers\n",
        "                    # Copy all encoder hidden layers and then repeat the top layer\n",
        "                    if cell_type == \"LSTM\":\n",
        "                        top_layer_hidden = (encoder_hidden[0][-1].unsqueeze(0), encoder_hidden[1][-1].unsqueeze(0))\n",
        "                        extra_hidden = (top_layer_hidden[0].repeat(remaining_layers, 1, 1), top_layer_hidden[1].repeat(remaining_layers, 1, 1))\n",
        "                        decoder_hidden = (torch.cat((encoder_hidden[0], extra_hidden[0]), dim=0), torch.cat((encoder_hidden[1], extra_hidden[1]), dim=0))\n",
        "                    else:\n",
        "                        top_layer_hidden = encoder_hidden[-1].unsqueeze(0) #top_layer_hidden shape (1, batch_size, hidden_size)\n",
        "                        extra_hidden = top_layer_hidden.repeat(remaining_layers, 1, 1)\n",
        "                        decoder_hidden = torch.cat((encoder_hidden, extra_hidden), dim=0)\n",
        "\n",
        "                else:\n",
        "                    # Slice the hidden states of the encoder to match the decoder layers\n",
        "                    if cell_type == \"LSTM\":\n",
        "                        decoder_hidden = (encoder_hidden[0][-decoder_num_layers:], encoder_hidden[1][-decoder_num_layers:])\n",
        "                    else :\n",
        "                        decoder_hidden = encoder_hidden[-decoder_num_layers:]\n",
        "            else:\n",
        "                decoder_hidden = encoder_hidden\n",
        "\n",
        "\n",
        "            loss = 0\n",
        "            pred=torch.zeros(len(target_tensor), batch_size).to(device)\n",
        "\n",
        "\n",
        "            for di in range(target_length):\n",
        "                decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "                decoder_output = torch.squeeze(decoder_output)\n",
        "                loss += criterion(decoder_output, target_tensor[di].long())\n",
        "\n",
        "\n",
        "                topv, topi = decoder_output.topk(1)\n",
        "                topi = torch.squeeze(topi)\n",
        "                pred[di]=topi\n",
        "                decoder_input = topi\n",
        "\n",
        "            pred = pred.T\n",
        "            act = target_tensor.T\n",
        "            act_eng = input_tensor.T\n",
        "            for i in range(batch_size):\n",
        "                pred_word=\"\"\n",
        "                input_word=\"\"\n",
        "                target_word = \"\"\n",
        "\n",
        "                f=0\n",
        "                for j in range(len(act[i])):\n",
        "\n",
        "                    if(int(pred[i][j].item()) > 2):\n",
        "                        pred_word += index2char[int(pred[i][j].item())]\n",
        "                    if(int(act[i][j].item()) > 2):\n",
        "                        target_word += index2char[int(act[i][j].item())]\n",
        "\n",
        "                    if(pred[i][j]!=act[i][j]):\n",
        "                        f=1\n",
        "\n",
        "                if(f==0):\n",
        "                    correct += 1\n",
        "\n",
        "                for j in range(len(act_eng[i])):\n",
        "\n",
        "                      if(int(act_eng[i][j].item()) > 2):\n",
        "                          input_word += index2char[int(act_eng[i][j].item())]\n",
        "\n",
        "                predictions.append(pred_word)\n",
        "                Input.append(input_word)\n",
        "                Target.append(target_word)\n",
        "\n",
        "\n",
        "        total_loss += loss\n",
        "        accuracy = correct / (len(val_loader) * batch_size )\n",
        "        final_loss = total_loss / (len(val_loader) * batch_size )\n",
        "    return  final_loss , accuracy , predictions ,Input , Target\n"
      ],
      "metadata": {
        "id": "o2hz9Lqt5bR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define training function\n",
        "def arguments(input_embedding_size,encoder_num_layers,decoder_num_layers,hidden_size,cell_type,bidirectional,batch_size,learning_rate,num_epochs,dropout,teacher_forcing_ratio,attention,beam_width,pathofzip,Folder_name):\n",
        "\n",
        "    train_dataset ,val_dataset ,test_dataset= Datasetretrival(pathofzip,Folder_name)\n",
        "\n",
        "    # Convert DataFrame to list of tuples\n",
        "    data_pairs_train = [list(row) for row in train_dataset.values]\n",
        "    data_pairs_val = [list(row) for row in val_dataset.values]\n",
        "    data_pairs_test = [list(row) for row in test_dataset.values]\n",
        "\n",
        "\n",
        "\n",
        "    index2char = {0:'<', 1: '>', 2 : '.'}\n",
        "    char2index = {'<' : 0, '>' : 1, '.' : 2 }\n",
        "\n",
        "\n",
        "    vec_pair_list_train,char2index, index2char,MAX_LENGTH_1=vecorizeddata(data_pairs_train,index2char, char2index)\n",
        "    vec_pair_list_val,_,_,MAX_LENGTH_2=vecorizeddata(data_pairs_val,index2char, char2index)\n",
        "    vec_pair_list_test,_,_,MAX_LENGTH_3=vecorizeddata(data_pairs_test,index2char, char2index)\n",
        "\n",
        "\n",
        "    predictions = []\n",
        "    Input = []\n",
        "    Target = []\n",
        "\n",
        "\n",
        "    MAX_LENGTH= 30\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    train_loader = DataLoader(vec_pair_list_train, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(vec_pair_list_val, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(vec_pair_list_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    # Define model\n",
        "    encoder = Encoder(len(char2index),input_embedding_size, hidden_size,batch_size, encoder_num_layers, cell_type,bidirectional, dropout).to(device)\n",
        "    decoder = Decoder(len(char2index),input_embedding_size, hidden_size,batch_size, decoder_num_layers, cell_type, dropout,MAX_LENGTH).to(device)\n",
        "    #model = Seq2Seq(encoder, decoder, encoder_num_layers, decoder_num_layers,batch_size, hidden_size,bidirectional, cell_type,device).to(device)\n",
        "\n",
        "    output_predictions=torch.tensor([]).to(device)\n",
        "    # Define loss function and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "        # Train the model\n",
        "        train_loss, train_accuracy = train(encoder,decoder, train_loader, encoder_optimizer,decoder_optimizer,encoder_num_layers,decoder_num_layers,cell_type, criterion,char2index,index2char,MAX_LENGTH,teacher_forcing_ratio,attention,beam_width, device)\n",
        "\n",
        "        # Validation loop\n",
        "        val_loss, val_accuracy,predictions ,Input , Target = evaluate(encoder,decoder, val_loader,encoder_num_layers,decoder_num_layers,cell_type, criterion,char2index,index2char,MAX_LENGTH,attention,beam_width, device)\n",
        "\n",
        "        # Log metrics to Weights & Biases\n",
        "        wandb.log({\n",
        "            \"Epoch\": epoch + 1,\n",
        "            \"Train_Accuracy\": train_accuracy,\n",
        "            \"Train_Loss\": train_loss,\n",
        "            \"Val_Accuracy\": val_accuracy,\n",
        "            \"Val_Loss\": val_loss\n",
        "        })\n",
        "\n",
        "        # Print epoch results\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs},\\n Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f},\\n Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\\n\")\n",
        "\n",
        "    print(f\"\\n Predictions Generated by current sweep and actual output:\\n\")\n",
        "    dataframe = pd.DataFrame({\"INPUT\": Input, \"PREDICTED\": predictions,\"ACTUAL\":Target})\n",
        "    dataframe.to_csv(\"predictions.csv\", index=False)\n",
        "    data = pd.read_csv(\"predictions.csv\",header=None)\n",
        "    #files.download(\"predictions.csv\")\n",
        "    display(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "Q-ogr2f5Hk8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#arguments(32,2,2,1024,\"RNN\",True,128,0.001,1,0.2,0.5,'/content/sample_data/aksharantar_sampled.zip','guj')"
      ],
      "metadata": {
        "id": "AdPJ4R11AYdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "id": "_uycA2lZ1b22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "945ace6f-abdd-45a2-cc39-163330ae8160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define hyperparameters to sweep\n",
        "sweep_config = {\n",
        "    \"method\": \"bayes\",\n",
        "    'name'  : 'Train Dataset Run',\n",
        "    'metric': {'goal': 'maximize', 'name': 'Val_Accuracy'},\n",
        "    \"parameters\": {\n",
        "        \"input_embedding_size\": {\"values\": [16, 32, 64, 256]},\n",
        "        \"encoder_num_layers\": {\"values\": [1, 2, 3]},\n",
        "        \"decoder_num_layers\": {\"values\": [1, 2, 3]},\n",
        "        \"hidden_size\": {\"values\": [128,256,512,1024]},\n",
        "        \"cell_type\": {\"values\": [\"RNN\", \"GRU\", \"LSTM\"]},\n",
        "        \"bidirectional\": {\"values\": [True, False]},\n",
        "        \"batch_size\": {\"values\": [32, 64 , 128]},\n",
        "        \"learning_rate\": {\"values\": [0.001, 0.0001]},\n",
        "        \"num_epochs\": {\"values\": [5,10 ,15]},\n",
        "        \"dropout\": {\"values\": [0.2, 0.3]},\n",
        "        \"teacher_forcing_ratio\" : {\"values\":[0.5]},\n",
        "        \"attention\": {\"values\": [False]},\n",
        "        \"beam_width\": {\"values\": [1,2,5,10,20]}\n",
        "    }\n",
        "}\n",
        "\n",
        "# Initialize wandb sweep\n",
        "sweep_id = wandb.sweep(sweep=sweep_config, project=\"DL_Assignment_3_CS23M046\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zLWJQje5FQ2s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1cfa9a2-7dde-44d2-91e1-40e0586c28cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: 7ulnwdt5\n",
            "Sweep URL: https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/sweeps/7ulnwdt5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main_1():\n",
        "\n",
        "    # Initialize wandb\n",
        "    with wandb.init() as run:\n",
        "\n",
        "        config = wandb.config\n",
        "\n",
        "        run_name=str(config.cell_type)+\"_embedding_\"+str(config.input_embedding_size)+\"_hidden_size_\"+str(config.hidden_size)+\"_bidirectional_\"+str(config.bidirectional)+\"_Encoder_layers_\"+str(config.encoder_num_layers)+\"_Decoder_layers_\"+str(config.decoder_num_layers)\n",
        "        wandb.run.name=run_name\n",
        "\n",
        "        pathofzip='/content/sample_data/aksharantar_sampled.zip'\n",
        "        Folder_name='guj'\n",
        "\n",
        "        arguments(config.input_embedding_size,config.encoder_num_layers,config.decoder_num_layers,config.hidden_size,config.cell_type,config.bidirectional,config.batch_size,config.learning_rate,config.num_epochs,config.dropout,config.teacher_forcing_ratio,config.attention,config.beam_width,pathofzip,Folder_name)\n",
        "\n",
        "\n",
        "\n",
        "# Run sweep\n",
        "wandb.agent(sweep_id, function=main_1, count=5)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "2FWR7pg3Mf55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f877006e5fce43809a9c660ea128e717",
            "68694ac4ff3e4d01b6beb9ec6a99f145",
            "19bed0682a81473a8a2038001ed0d495",
            "5e07f34785e447cdb42ac3f2c6505f34",
            "d7759284d5e84508b5fb576b6720d1f1",
            "8a74a887c3c74c1a900303b73934fc63",
            "bc69c175a4a949d88174ab5695a91cac",
            "413fbe6342674d8386042992fd26fe44"
          ]
        },
        "outputId": "024be357-4af5-462f-e44d-e1f6916ebcaa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jb085a8c with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_num_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_num_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240507_095401-jb085a8c</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/runs/jb085a8c' target=\"_blank\">celestial-sweep-1</a></strong> to <a href='https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/sweeps/7ulnwdt5' target=\"_blank\">https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/sweeps/7ulnwdt5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046' target=\"_blank\">https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/sweeps/7ulnwdt5' target=\"_blank\">https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/sweeps/7ulnwdt5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/runs/jb085a8c' target=\"_blank\">https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/runs/jb085a8c</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
            "100%|██████████| 1600/1600 [01:11<00:00, 22.28it/s]\n",
            "100%|██████████| 128/128 [00:13<00:00,  9.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/10,\n",
            " Train Loss: 0.9623, Train Accuracy: 0.0000,\n",
            " Val Loss: 0.0062, Val Accuracy: 0.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1600/1600 [01:15<00:00, 21.22it/s]\n",
            "100%|██████████| 128/128 [00:13<00:00,  9.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/10,\n",
            " Train Loss: 0.8326, Train Accuracy: 0.0000,\n",
            " Val Loss: 0.0062, Val Accuracy: 0.0005\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1600/1600 [01:12<00:00, 21.99it/s]\n",
            "100%|██████████| 128/128 [00:13<00:00,  9.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3/10,\n",
            " Train Loss: 0.8101, Train Accuracy: 0.0000,\n",
            " Val Loss: 0.0064, Val Accuracy: 0.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1600/1600 [01:11<00:00, 22.23it/s]\n",
            "100%|██████████| 128/128 [00:13<00:00,  9.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4/10,\n",
            " Train Loss: 0.8044, Train Accuracy: 0.0000,\n",
            " Val Loss: 0.0065, Val Accuracy: 0.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1600/1600 [01:13<00:00, 21.86it/s]\n",
            "100%|██████████| 128/128 [00:13<00:00,  9.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5/10,\n",
            " Train Loss: 0.7918, Train Accuracy: 0.0000,\n",
            " Val Loss: 0.0064, Val Accuracy: 0.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1600/1600 [01:11<00:00, 22.36it/s]\n",
            "100%|██████████| 128/128 [00:13<00:00,  9.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 6/10,\n",
            " Train Loss: 0.7907, Train Accuracy: 0.0000,\n",
            " Val Loss: 0.0064, Val Accuracy: 0.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1600/1600 [01:12<00:00, 22.17it/s]\n",
            "100%|██████████| 128/128 [00:13<00:00,  9.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 7/10,\n",
            " Train Loss: 0.7822, Train Accuracy: 0.0000,\n",
            " Val Loss: 0.0062, Val Accuracy: 0.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1600/1600 [01:12<00:00, 22.07it/s]\n",
            "100%|██████████| 128/128 [00:13<00:00,  9.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 8/10,\n",
            " Train Loss: 0.7813, Train Accuracy: 0.0000,\n",
            " Val Loss: 0.0062, Val Accuracy: 0.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1600/1600 [01:12<00:00, 22.21it/s]\n",
            "100%|██████████| 128/128 [00:13<00:00,  9.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 9/10,\n",
            " Train Loss: 0.7760, Train Accuracy: 0.0000,\n",
            " Val Loss: 0.0064, Val Accuracy: 0.0000\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1600/1600 [01:11<00:00, 22.29it/s]\n",
            "100%|██████████| 128/128 [00:13<00:00,  9.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 10/10,\n",
            " Train Loss: 0.7770, Train Accuracy: 0.0000,\n",
            " Val Loss: 0.0062, Val Accuracy: 0.0000\n",
            "\n",
            "\n",
            " Predictions Generated by current sweep and actual output:\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                 0          1            2\n",
              "0            INPUT  PREDICTED       ACTUAL\n",
              "1         vasteena     વિલ્લા       વસતીના\n",
              "2        gardanana     ગ્રાના       ગરદનના\n",
              "3            roqsa     રાજ્ાા        રોક્સ\n",
              "4     suparastarsa    સ્ટ્રાન  સુપરસ્ટાર્સ\n",
              "...            ...        ...          ...\n",
              "4092      humirsir     હાર્ાા       હમીરસર\n",
              "4093        batata     બારાના        બટાટા\n",
              "4094       dhovaai     ધર્માા        ધોવાઇ\n",
              "4095    daridrataa     દેવાાા     દરિદ્રતા\n",
              "4096   ekantbharya  એન્ટ્રેટ્   એકાંતભર્યા\n",
              "\n",
              "[4097 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a839d568-ecfe-4b9c-b543-b7b8d3abfcd0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INPUT</td>\n",
              "      <td>PREDICTED</td>\n",
              "      <td>ACTUAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>vasteena</td>\n",
              "      <td>વિલ્લા</td>\n",
              "      <td>વસતીના</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gardanana</td>\n",
              "      <td>ગ્રાના</td>\n",
              "      <td>ગરદનના</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>roqsa</td>\n",
              "      <td>રાજ્ાા</td>\n",
              "      <td>રોક્સ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>suparastarsa</td>\n",
              "      <td>સ્ટ્રાન</td>\n",
              "      <td>સુપરસ્ટાર્સ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4092</th>\n",
              "      <td>humirsir</td>\n",
              "      <td>હાર્ાા</td>\n",
              "      <td>હમીરસર</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4093</th>\n",
              "      <td>batata</td>\n",
              "      <td>બારાના</td>\n",
              "      <td>બટાટા</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4094</th>\n",
              "      <td>dhovaai</td>\n",
              "      <td>ધર્માા</td>\n",
              "      <td>ધોવાઇ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4095</th>\n",
              "      <td>daridrataa</td>\n",
              "      <td>દેવાાા</td>\n",
              "      <td>દરિદ્રતા</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4096</th>\n",
              "      <td>ekantbharya</td>\n",
              "      <td>એન્ટ્રેટ્</td>\n",
              "      <td>એકાંતભર્યા</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4097 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a839d568-ecfe-4b9c-b543-b7b8d3abfcd0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a839d568-ecfe-4b9c-b543-b7b8d3abfcd0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a839d568-ecfe-4b9c-b543-b7b8d3abfcd0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bfa5d9f3-e454-4148-a015-4bd414939810\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bfa5d9f3-e454-4148-a015-4bd414939810')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bfa5d9f3-e454-4148-a015-4bd414939810 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"wandb\",\n  \"rows\": 4097,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4087,\n        \"samples\": [\n          \"pahormaa\",\n          \"laleemaa\",\n          \"karoonateeka\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 42,\n        \"samples\": [\n          \"\\u0ab2\\u0ac7\\u0a95\\u0acd\\u0a9f\\u0ab0\",\n          \"\\u0a8f\\u0aa8\\u0acd\\u0a9f\\u0acd\\u0ab0\\u0ac7\\u0a9f\\u0acd\",\n          \"\\u0a95\\u0abe\\u0ab0\\u0acd\\u0aa8\\u0abe\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2521,\n        \"samples\": [\n          \"\\u0a85\\u0a82\\u0a97\\u0acd\\u0ab0\\u0ac7\\u0a9c\\u0ac0\\u0aae\\u0abe\\u0a82\\u0aa5\\u0ac0\",\n          \"\\u0aac\\u0aac\\u0ab2\",\n          \"\\u0aad\\u0ac2\\u0aa4\\u0abe\\u0aa8\\u0aae\\u0abe\\u0a82\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f877006e5fce43809a9c660ea128e717"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>Train_Accuracy</td><td>▁█▁▁█▁█▁▁▁</td></tr><tr><td>Train_Loss</td><td>█▃▂▂▂▂▁▁▁▁</td></tr><tr><td>Val_Accuracy</td><td>▁█▁▁▁▁▁▁▁▁</td></tr><tr><td>Val_Loss</td><td>▃▃██▆▆▁▂▆▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>10</td></tr><tr><td>Train_Accuracy</td><td>0.0</td></tr><tr><td>Train_Loss</td><td>0.77697</td></tr><tr><td>Val_Accuracy</td><td>0.0</td></tr><tr><td>Val_Loss</td><td>0.0062</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">celestial-sweep-1</strong> at: <a href='https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/runs/jb085a8c' target=\"_blank\">https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/runs/jb085a8c</a><br/> View project at: <a href='https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046' target=\"_blank\">https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240507_095401-jb085a8c/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3conytqa with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tattention: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbidirectional: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_num_layers: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_num_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinput_embedding_size: 16\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_epochs: 5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing_ratio: 0.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240507_100838-3conytqa</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/runs/3conytqa' target=\"_blank\">royal-sweep-2</a></strong> to <a href='https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/sweeps/7ulnwdt5' target=\"_blank\">https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/sweeps/7ulnwdt5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046' target=\"_blank\">https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/sweeps/7ulnwdt5' target=\"_blank\">https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/sweeps/7ulnwdt5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/runs/3conytqa' target=\"_blank\">https://wandb.ai/cs23m046/DL_Assignment_3_CS23M046/runs/3conytqa</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:43<00:00, 18.36it/s]\n",
            "100%|██████████| 64/64 [00:13<00:00,  4.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/5,\n",
            " Train Loss: 0.4371, Train Accuracy: 0.0003,\n",
            " Val Loss: 0.0043, Val Accuracy: 0.0056\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:43<00:00, 18.42it/s]\n",
            "100%|██████████| 64/64 [00:14<00:00,  4.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2/5,\n",
            " Train Loss: 0.3250, Train Accuracy: 0.0029,\n",
            " Val Loss: 0.0037, Val Accuracy: 0.0217\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 800/800 [00:44<00:00, 18.09it/s]\n",
            " 59%|█████▉    | 38/64 [00:08<00:05,  4.80it/s]"
          ]
        }
      ]
    }
  ]
}